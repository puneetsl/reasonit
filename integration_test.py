#!/usr/bin/env python3
"""
Integration test showing Self-Proving Module with ReasonIt agents.

This demonstrates how the Self-Proving Module can verify reasoning
outputs from the existing ReasonIt reasoning agents.
"""

import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from agents import ChainOfThoughtAgent
from models.openai_wrapper import OpenAIWrapper
from proofs import CertificateGenerator, CertificateLevel, ProofType


def test_cot_with_verification():
    """Test Chain of Thought agent with Self-Proving verification."""
    print("ğŸ”— CHAIN OF THOUGHT + SELF-PROVING INTEGRATION")
    print("=" * 60)
    
    # Initialize components
    model = OpenAIWrapper(model_name="gpt-4o-mini")
    cot_agent = ChainOfThoughtAgent(model=model)
    cert_generator = CertificateGenerator()
    
    # Test problem
    problem = "If 3 people each eat 2 apples, and then 2 more people each eat 1 apple, how many apples were eaten in total?"
    
    print(f"Problem: {problem}\n")
    
    # Get reasoning from CoT agent
    print("ğŸ§  Chain of Thought Reasoning:")
    result = cot_agent.reason(problem)
    
    print(f"  Final Answer: {result.final_answer}")
    print(f"  Confidence: {result.confidence:.1%}")
    print(f"  Steps: {len(result.reasoning_steps)}")
    
    print("\n  Reasoning Steps:")
    for i, step in enumerate(result.reasoning_steps, 1):
        print(f"    {i}. {step}")
    
    # Create reasoning trace for verification
    reasoning_trace = result.reasoning_steps + [f"Therefore: {result.final_answer}"]
    
    # Generate verification certificate
    print(f"\nğŸ”§ Self-Proving Verification:")
    certificate = cert_generator.generate_certificate(
        claim=result.final_answer,
        reasoning_trace=reasoning_trace,
        certificate_level=CertificateLevel.STANDARD,
        proof_type=ProofType.MATHEMATICAL_PROOF
    )
    
    print(f"  Certificate Status: {certificate.status.value.upper()}")
    print(f"  Trustworthiness: {certificate.metrics.overall_trustworthiness:.1%}")
    print(f"  Mathematical Correctness: {certificate.metrics.mathematical_correctness:.1%}")
    print(f"  Proof Confidence: {certificate.metrics.proof_confidence:.1%}")
    
    # Show verification details
    if certificate.verification_report:
        report = certificate.verification_report
        print(f"\nğŸ“Š Verification Analysis:")
        print(f"  Verification Result: {report.result.value.upper()}")
        print(f"  Overall Score: {report.overall_score:.1%}")
        print(f"  Logical Consistency: {report.logical_consistency_score:.1%}")
        print(f"  Mathematical Score: {report.mathematical_correctness_score:.1%}")
        
        if report.errors_found:
            print(f"  âŒ Errors Found:")
            for error in report.errors_found:
                print(f"    â€¢ {error}")
        
        if report.recommendations:
            print(f"  ğŸ’¡ Recommendations:")
            for rec in report.recommendations[:2]:
                print(f"    â€¢ {rec}")
    
    print(f"\nâœ… Integration test completed successfully!\n")
    
    return {
        'original_result': result,
        'certificate': certificate,
        'verified': certificate.status.value == 'valid'
    }


def test_logical_problem_verification():
    """Test logical reasoning problem with verification."""
    print("ğŸ§  LOGICAL REASONING VERIFICATION")
    print("=" * 60)
    
    model = OpenAIWrapper(model_name="gpt-4o-mini")
    cot_agent = ChainOfThoughtAgent(model=model)
    cert_generator = CertificateGenerator()
    
    # Logical reasoning problem
    problem = """
    All cats are mammals.
    All mammals are warm-blooded.
    Whiskers is a cat.
    What can we conclude about Whiskers?
    """
    
    print(f"Problem: {problem.strip()}\n")
    
    # Get reasoning from CoT agent
    print("ğŸ§  Chain of Thought Analysis:")
    result = cot_agent.reason(problem)
    
    print(f"  Final Answer: {result.final_answer}")
    print(f"  Confidence: {result.confidence:.1%}")
    
    print("\n  Reasoning Steps:")
    for i, step in enumerate(result.reasoning_steps, 1):
        print(f"    {i}. {step}")
    
    # Verify with Self-Proving Module
    reasoning_trace = result.reasoning_steps + [f"Conclusion: {result.final_answer}"]
    
    print(f"\nğŸ”§ Formal Verification:")
    certificate = cert_generator.generate_certificate(
        claim=result.final_answer,
        reasoning_trace=reasoning_trace,
        certificate_level=CertificateLevel.PREMIUM,
        proof_type=ProofType.LOGICAL_INFERENCE
    )
    
    print(f"  Certificate Level: {certificate.certificate_level.value.upper()}")
    print(f"  Status: {certificate.status.value.upper()}")
    print(f"  Trustworthiness: {certificate.metrics.overall_trustworthiness:.1%}")
    print(f"  Logical Consistency: {certificate.metrics.logical_consistency:.1%}")
    print(f"  Semantic Coherence: {certificate.metrics.semantic_coherence:.1%}")
    
    # Show proof analysis
    if certificate.proof_certificate:
        proof = certificate.proof_certificate
        print(f"\nğŸ“‹ Proof Certificate:")
        print(f"  Proof Steps: {len(proof.steps)}")
        print(f"  Premises: {len(proof.premises)}")
        print(f"  Validity Score: {proof.validity_score:.1%}")
        print(f"  Completeness: {proof.completeness_score:.1%}")
        
        # Show identified inference rules
        rules = set(step.inference_rule for step in proof.steps)
        print(f"  Inference Rules: {', '.join(rules)}")
    
    print(f"\nâœ… Logical reasoning verification completed!\n")
    
    return {
        'original_result': result,
        'certificate': certificate,
        'verified': certificate.status.value == 'valid'
    }


def comparative_analysis():
    """Compare different reasoning approaches with verification."""
    print("ğŸ“Š COMPARATIVE REASONING ANALYSIS")
    print("=" * 60)
    
    cert_generator = CertificateGenerator()
    
    # Test different reasoning approaches for the same problem
    problem = "If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?"
    
    reasoning_approaches = [
        {
            "name": "Direct Calculation",
            "steps": [
                "5 machines make 5 widgets in 5 minutes",
                "This means each machine makes 1 widget in 5 minutes",
                "Rate per machine: 1 widget per 5 minutes",
                "100 machines would each make 1 widget in 5 minutes",
                "Therefore: 100 machines make 100 widgets in 5 minutes"
            ],
            "answer": "5 minutes"
        },
        {
            "name": "Proportional Reasoning", 
            "steps": [
                "Given: 5 machines â†’ 5 widgets in 5 minutes",
                "Find: 100 machines â†’ 100 widgets in ? minutes",
                "Ratio of machines: 100/5 = 20",
                "Ratio of widgets: 100/5 = 20",
                "Since both ratios are equal, time remains the same",
                "Therefore: 100 machines make 100 widgets in 5 minutes"
            ],
            "answer": "5 minutes"
        },
        {
            "name": "Rate Analysis",
            "steps": [
                "Production rate: 5 widgets / (5 machines Ã— 5 minutes) = 1 widget per machine-minute",
                "For 100 widgets: need 100 machine-minutes",
                "With 100 machines: 100 machine-minutes / 100 machines = 1 minute",
                "Wait, that's wrong. Let me recalculate:",
                "Actually: 1 widget per 5 machine-minutes",
                "100 widgets need 500 machine-minutes",
                "100 machines provide 500 machine-minutes in 5 minutes",
                "Therefore: 5 minutes"
            ],
            "answer": "5 minutes"
        }
    ]
    
    print(f"Problem: {problem}\n")
    
    results = []
    
    for approach in reasoning_approaches:
        print(f"ğŸ” Testing: {approach['name']}")
        
        # Generate certificate for this approach
        certificate = cert_generator.generate_certificate(
            claim=approach['answer'],
            reasoning_trace=approach['steps'],
            certificate_level=CertificateLevel.STANDARD,
            proof_type=ProofType.MATHEMATICAL_PROOF
        )
        
        results.append({
            'name': approach['name'],
            'answer': approach['answer'],
            'status': certificate.status.value,
            'trustworthiness': certificate.metrics.overall_trustworthiness,
            'mathematical_correctness': certificate.metrics.mathematical_correctness,
            'logical_consistency': certificate.metrics.logical_consistency,
            'steps': len(approach['steps'])
        })
        
        print(f"  Answer: {approach['answer']}")
        print(f"  Status: {certificate.status.value.upper()}")
        print(f"  Trustworthiness: {certificate.metrics.overall_trustworthiness:.1%}")
        print(f"  Math Correctness: {certificate.metrics.mathematical_correctness:.1%}")
        print("")
    
    # Display comparison
    print("ğŸ“‹ VERIFICATION COMPARISON:")
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Approach            â”‚ Answer      â”‚ Status   â”‚ Trustworthiness  â”‚ Math Correctness    â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for result in results:
        print(f"â”‚ {result['name']:19} â”‚ {result['answer']:11} â”‚ {result['status']:8} â”‚ {result['trustworthiness']:15.1%} â”‚ {result['mathematical_correctness']:18.1%} â”‚")
    
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    print(f"\nğŸ’¡ Analysis:")
    valid_approaches = [r for r in results if r['status'] == 'valid']
    if valid_approaches:
        best_approach = max(valid_approaches, key=lambda x: x['trustworthiness'])
        print(f"  â€¢ Best verified approach: {best_approach['name']}")
        print(f"  â€¢ Highest trustworthiness: {best_approach['trustworthiness']:.1%}")
    
    consistent_answers = len(set(r['answer'] for r in results))
    print(f"  â€¢ Answer consistency: {len(results) - consistent_answers + 1}/{len(results)} approaches agree")
    
    print(f"\nâœ… Comparative analysis completed!\n")
    
    return results


def main():
    """Run integration tests between ReasonIt agents and Self-Proving Module."""
    print("ğŸ”§ ReasonIt Integration with Self-Proving Module")
    print("=" * 70)
    print("Testing integration between reasoning agents and formal verification\n")
    
    try:
        # Test mathematical reasoning
        math_result = test_cot_with_verification()
        
        # Test logical reasoning
        logic_result = test_logical_problem_verification()
        
        # Comparative analysis
        comparison_results = comparative_analysis()
        
        print("ğŸ‰ INTEGRATION TESTING COMPLETED!")
        print("\nResults Summary:")
        print(f"  Mathematical Problem: {'âœ… VERIFIED' if math_result['verified'] else 'âŒ FAILED'}")
        print(f"  Logical Problem: {'âœ… VERIFIED' if logic_result['verified'] else 'âŒ FAILED'}")
        print(f"  Comparative Analysis: âœ… COMPLETED")
        
        print(f"\nKey Achievements:")
        print(f"  âœ… Successfully integrated CoT agent with Self-Proving verification")
        print(f"  âœ… Demonstrated mathematical reasoning verification")
        print(f"  âœ… Showed logical reasoning analysis capabilities")
        print(f"  âœ… Performed comparative verification across multiple approaches")
        print(f"  âœ… Generated formal certificates for reasoning outputs")
        
        print(f"\nThe Self-Proving Module is fully operational and ready to provide")
        print(f"formal verification for any reasoning output from ReasonIt agents!")
        
    except Exception as e:
        print(f"âŒ Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)